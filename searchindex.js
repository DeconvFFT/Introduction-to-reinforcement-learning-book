Search.setIndex({docnames:["Tabular-MDPs/MDP","Tabular-MDPs/value-iteration","intro","references"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":4,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":3,"sphinx.domains.rst":2,"sphinx.domains.std":2,"sphinx.ext.intersphinx":1,"sphinxcontrib.bibtex":9,sphinx:56},filenames:["Tabular-MDPs/MDP.md","Tabular-MDPs/value-iteration.md","intro.md","references.md"],objects:{},objnames:{},objtypes:{},terms:{"2":[],"case":2,"function":2,"return":2,"while":2,A:2,And:[],At:2,In:2,It:2,The:2,There:2,a_t:2,abcdef:[],abl:2,action:[],adjust:2,agent:2,allow:2,also:2,an:2,angl:2,ar:2,aspect:[],atari:2,avail:2,bad:2,behaviour:2,block:[],book:[],bundl:[],call:2,can:2,chang:2,charact:2,check:[],choos:2,code:[],complet:2,complex:2,content:[],continu:2,cover:[],cumul:2,current:2,decid:2,defin:2,denot:2,depend:2,descript:2,determinist:2,discret:2,e:[],environ:2,error:2,everi:2,exampl:2,finit:2,forgo:2,from:2,fulli:2,futur:2,game:2,geenral:2,goal:2,good:2,hand:2,have:2,here:[],how:2,inform:2,interact:2,intro:1,joint:2,label:[],like:2,lot:2,mai:2,main:2,make:2,matrix:2,maxim:2,mayb:2,mc:[],more:2,mu:2,mu_:2,navig:2,need:2,number:2,observ:2,onli:2,order:2,other:2,out:[],output:2,page:[],paramet:2,parameter:2,partial:2,phi:2,physic:2,pi:2,pi_:2,pixel:2,practic:[],punish:2,random:2,read:[],real:2,reciev:2,refer:1,remov:2,repeat:2,repres:2,reward:2,rgb:2,robot:2,rule:2,s:2,s_t:2,sampl:[1,2],see:2,set:2,signal:2,sim:2,similar:[],some:[1,2],state:[],step:2,stochast:2,studi:2,take:2,taken:2,tell:2,text:1,thei:2,theoret:[],theta:2,thi:1,trajectori:2,trial:2,us:2,valid:2,valu:2,vector:2,veloc:2,version:2,we:2,well:2,when:2,where:2,which:2,widetild:[],world:2,would:2,written:2},titles:["Markov Decision Process","Value Iteration","Introduction to Reinforcement Learning","Articles and blogposts referenced"],titleterms:{action:2,articl:3,blogpost:3,concept:2,decis:0,first:1,here:1,introduct:2,iter:1,kei:2,learn:2,markov:0,my:1,polici:2,process:0,refer:[],referenc:3,reinforc:2,s:1,sampl:[],section:1,space:2,state:2,titl:[],valu:1,what:2}})